{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from MyNLP import WordDividerMecab\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/2023_01_04/kakogawa_baibasu_ziko_comment2.csv\", encoding=\"cp932\", header=None)\n",
    "comment_list = []\n",
    "row_data = df[0][1:].to_numpy().tolist()\n",
    "temp_row_data = []\n",
    "for text in row_data:\n",
    "    if len(text) >= 50:\n",
    "        temp_row_data.append(text)\n",
    "row_data = temp_row_data\n",
    "wd = WordDividerMecab()\n",
    "stop_word_list = [\"まだ\", \"ある\", \"なる\", \"なる\", \"する\", \"し\", \"する\", \"いる\", \"なっ\", \"せ\", \"い\", \"やる\", \"ない\"]\n",
    "for text in row_data:\n",
    "    if len(text) >= 10:\n",
    "        text = wd.wakati_text_delete(text=text, stop_word_list=stop_word_list)\n",
    "        comment_list.append(text)\n",
    "dataset = [comment.split() for comment in comment_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1902\n",
      "428\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary(dataset)\n",
    "print(len(dictionary))\n",
    "\n",
    "dictionary.filter_extremes(no_below=3, no_above=0.1)\n",
    "print(len(dictionary))\n",
    "\n",
    "score_by_topic = defaultdict(int)\n",
    "corpus = [dictionary.doc2bow(text) for text in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 0.94373983)]\n"
     ]
    }
   ],
   "source": [
    "lda = LdaModel(corpus=corpus, num_topics=10, id2word=dictionary)\n",
    "#lda.show_topics()\n",
    "print(lda[corpus[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.030*\"バイパス\" + 0.014*\"わかる\" + 0.013*\"衝突\" + 0.013*\"前方\" + 0.013*\"いい\" + 0.013*\"分かる\" + 0.013*\"車外\" + 0.013*\"三重\" + 0.013*\"軽乗用車\" + 0.013*\"高速\"'),\n",
       " (1,\n",
       "  '0.023*\"安全\" + 0.017*\"移動\" + 0.017*\"運転手\" + 0.016*\"居眠り\" + 0.015*\"母親\" + 0.013*\"トラック運転手\" + 0.013*\"普通車\" + 0.012*\"命\" + 0.012*\"乗せる\" + 0.012*\"痛ましい\"'),\n",
       " (2,\n",
       "  '0.025*\"衝突\" + 0.021*\"悪い\" + 0.019*\"成る\" + 0.014*\"安全性\" + 0.014*\"仕事\" + 0.013*\"高速\" + 0.013*\"停止\" + 0.012*\"日本\" + 0.011*\"乗る\" + 0.010*\"スマホ\"'),\n",
       " (3,\n",
       "  '0.016*\"母親\" + 0.014*\"不注意\" + 0.014*\"チャイルドシート\" + 0.013*\"乗る\" + 0.011*\"痛ましい\" + 0.011*\"トラック運転手\" + 0.011*\"思える\" + 0.011*\"気\" + 0.011*\"2人\" + 0.011*\"気付く\"'),\n",
       " (4,\n",
       "  '0.020*\"場合\" + 0.018*\"考える\" + 0.016*\"出す\" + 0.016*\"出る\" + 0.016*\"前方\" + 0.015*\"不注意\" + 0.013*\"外\" + 0.012*\"車線\" + 0.011*\"持つ\" + 0.011*\"*\"'),\n",
       " (5,\n",
       "  '0.017*\"夜中\" + 0.016*\"接触\" + 0.016*\"母親\" + 0.013*\"衝突\" + 0.013*\"気の毒\" + 0.012*\"ぶつかる\" + 0.012*\"避ける\" + 0.010*\"ハザード\" + 0.010*\"いい\" + 0.010*\"軽乗用車\"'),\n",
       " (6,\n",
       "  '0.024*\"加古川バイパス\" + 0.019*\"バイパス\" + 0.016*\"車間\" + 0.015*\"距離\" + 0.015*\"接触\" + 0.013*\"危険\" + 0.012*\"出る\" + 0.011*\"大きい\" + 0.010*\"しれる\" + 0.010*\"二\"'),\n",
       " (7,\n",
       "  '0.022*\"乗る\" + 0.017*\"ぶつかる\" + 0.017*\"2歳\" + 0.016*\"スマホ\" + 0.015*\"助かる\" + 0.015*\"子\" + 0.015*\"1歳\" + 0.014*\"考える\" + 0.013*\"亡くなる\" + 0.012*\"衝突\"'),\n",
       " (8,\n",
       "  '0.046*\"ドライバー\" + 0.021*\"自動ブレーキ\" + 0.015*\"出る\" + 0.013*\"バイパス\" + 0.013*\"絶対\" + 0.013*\"走行\" + 0.013*\"気\" + 0.011*\"2歳\" + 0.011*\"違う\" + 0.011*\"帰る\"'),\n",
       " (9,\n",
       "  '0.022*\"しれる\" + 0.020*\"記事\" + 0.020*\"高い\" + 0.019*\"つける\" + 0.016*\"危険\" + 0.016*\"軽\" + 0.015*\"チャイルドシート\" + 0.013*\"乗用車\" + 0.012*\"運転手\" + 0.012*\"書く\"')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_info = lda.print_topics(num_topics=258, num_words=10)\n",
    "topic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1      2      3    4      5      6      7    8    9\n",
      "0  0.0  0.0  0.000  0.000  0.0  0.962  0.000  0.000  0.0  0.0\n",
      "1  0.0  0.0  0.000  0.872  0.0  0.000  0.093  0.000  0.0  0.0\n",
      "2  0.0  0.0  0.000  0.000  0.0  0.000  0.000  0.953  0.0  0.0\n",
      "3  0.0  0.0  0.000  0.000  0.0  0.944  0.000  0.000  0.0  0.0\n",
      "4  0.0  0.0  0.961  0.000  0.0  0.000  0.000  0.000  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "topic_df = pd.DataFrame(index = range(len(corpus)))\n",
    "\n",
    "for c in range(10):\n",
    "    topic_df[c] = 0.0\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    topics = lda[corpus[i]]\n",
    "    for t, p in topics:\n",
    "        topic_df.loc[i][t] = p\n",
    "        \n",
    "print(topic_df.head().round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
